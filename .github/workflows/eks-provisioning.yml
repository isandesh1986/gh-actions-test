name: eks-provisioning

on: 
  workflow_dispatch:
    inputs:
      cluster_name:
        description: 'Name for the cluster.'
        required: true
        type: string
        default: gh-actions-eks-cluster1
      s3_bucket:
        description: 'Name of the S3 bucket where the Terraform state of the cluster will be stored.'
        required: true
        type: string
        default: workflow-eks-state
      s3_keypath:
        description: 'Path within the S3 bucket where the Terraform state of the cluster will be stored.'
        required: true
        type: string
        default: eks/tf.state
      aws_region:
        description: 'AWS Region where to provision resources.'
        required: true
        type: string
        default: eu-west-1
      install_rancher:
        description: 'Installs Rancher on EKS when set to true.'
        required: true
        type: string
        default: true  

env:
  TERRAFORM_WORKING_DIRECTORY: ".terraform/eks"

jobs:
  terraform-actions:
    name: Provisioning EKS
    runs-on: ubuntu-latest
    steps:
    - name: Checkout Repository
      uses: actions/checkout@master

    - name: Configure AWS Credentials
      uses: aws-actions/configure-aws-credentials@v1
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ github.event.inputs.aws_region }}

#     - name: Terraform Init
#       id: init
#       working-directory: ${{ env.TERRAFORM_WORKING_DIRECTORY }}
#       run: terraform init -backend-config=bucket=${{ github.event.inputs.s3_bucket }} -backend-config=key=${{ github.event.inputs.s3_keypath }} -backend-config=region=${{ github.event.inputs.aws_region }}
#       continue-on-error: false

#     - name: Terraform Apply
#       id: apply
#       working-directory: ${{ env.TERRAFORM_WORKING_DIRECTORY }}
#       run: terraform apply -var 'cluster_name=${{ github.event.inputs.cluster_name }}' --auto-approve
#       continue-on-error: false
      
#     - name: Install NGINX Ingress controller
#       id: installnginx
#       run: |      
#         aws eks update-kubeconfig --name ${{ github.event.inputs.cluster_name }} --region ${{ github.event.inputs.aws_region }}        
#         helm repo add bitnami "https://charts.bitnami.com/bitnami"        
#         helm repo update        
#         helm upgrade --install nginx-ingress "nginx-ingress-controller" --set ingressClassResource.default=true --set containerSecurityContext.allowPrivilegeEscalation=false --repo "https://charts.bitnami.com/bitnami" --namespace nginx-ingress --create-namespace
      
    - name: Obtain Ingress Controller domain name
      id: obtaindns
      run: | 
       aws eks update-kubeconfig --name ${{ github.event.inputs.cluster_name }} --region ${{ github.event.inputs.aws_region }}
       dnsname=$(.github/workflows/scripts/obtain-dns.sh)
       echo "::set-output name=dnsname::$dnsname"
  
    - name: Publish Ingress Controller domain name
      id: publishdns
      run: |
        cd .github
        mkdir vars
        cd vars
        touch "eks_variables.env"
        echo "cluster_name=${{ github.event.inputs.cluster_name }}" >> eks_variables.env
        echo "dns_name=${{ steps.obtaindns.outputs.dnsname }}" >> eks_variables.env
      
    - uses: EndBug/add-and-commit@v7
      with:
        default_author: github_actions
        cwd: '.github/vars/'
        
    - name: Install Rancher
      id: installrancher
      if: ${{ github.event.inputs.install_rancher == 'true' }}
      run: |
        .github/workflows/scripts/install-rancher.sh ${{ steps.obtaindns.outputs.dnsname }}
